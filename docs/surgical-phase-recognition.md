
1. OperA: Attention-Regularized Transformers for Surgical Phase Recognition, TU Munchen (2021)

Methodology:
- CNN: ResNet-50 feature extractor.
- Transformer: Transformers have the capabilities to model long sequences in a parallel manner using self-attention by relating every input feature with other input features regardless of
their distance in the sequence.

Pros and Cons:
- Outperforms other temporal refinement methods (LSTM)
- Evaluate OperA on two challenging surgical video datasets (Cholec80, MitiSW)

Data:
- Cholec80
- MitiSW